{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\이지수\\appdata\\roaming\\python\\python39\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\이지수\\appdata\\roaming\\python\\python39\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\이지수\\appdata\\roaming\\python\\python39\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import astype_to_category, convert_category_into_integer\n",
    "from src.model.decision_tree import decision_tree\n",
    "from src.model.logistic_regression import logit\n",
    "from src.model.svm import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.datasets as ds\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7176738576979766, 0.7149269730671312)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "## train, test 데이터 불러오기\n",
    "origin_train = pd.read_csv('../data/train.csv', encoding='cp949').dropna()\n",
    "origin_test = pd.read_csv('../data/test.csv', encoding='cp949')\n",
    "drop_columns = ['HandsetRefurbished', 'HandsetWebCapable', 'ServiceArea', 'ChildrenInHH', 'TruckOwner', 'RVOwner', 'Homeownership', 'BuysViaMailOrder', 'RespondsToMailOffers', 'OptOutMailings', 'NonUSTravel', 'OwnsComputer', 'HasCreditCard', 'NewCellphoneUser', 'NotNewCellphoneUser', 'NonUSTravel', 'MadeCallToRetentionTeam', 'OwnsMotorcycle', 'CreditRating', 'MaritalStatus', 'Occupation', 'PrizmCode']\n",
    "origin_train = origin_train.drop(columns=drop_columns)\n",
    "origin_test = origin_test.drop(columns=drop_columns)\n",
    "# filter_columns = ['Churn', 'MonthlyRevenue', 'TotalRecurringCharge', 'PercChangeRevenues', 'IncomeGroup', 'MonthlyMinutes', 'DroppedCalls',\\\n",
    "#                    'BlockedCalls', 'OverageMinutes', 'RoamingCalls', 'CustomerCareCalls', 'RetentionCalls', 'MonthsInService',\\\n",
    "#                       'HandsetRefurbished', 'HandsetWebCapable', 'Homeownership', 'NewCellphoneUser', 'AgeHH1', \\\n",
    "#                         'AgeHH2', 'CreditRating', 'AdjustmentsToCreditRating', 'HasCreditCard']\n",
    "# origin_train = origin_train.filter(items=filter_columns)\n",
    "# origin_train = origin_train.filter(items=filter_columns)\n",
    "\n",
    "origin_train = origin_train.query(\"MonthlyRevenue < 100\")\n",
    "origin_train = origin_train.query(\"MonthlyMinutes < 1200\")\n",
    "origin_train = origin_train.query(\"OverageMinutes < 20\")\n",
    "origin_train = origin_train.query(\"-10 < PercChangeRevenues < 0\")\n",
    "origin_train = origin_train.query(\"ActiveSubs < 6\")\n",
    "origin_train = origin_train.query(\"HandsetModels < 4\")\n",
    "origin_train = origin_train.query(\"MonthsInService < 50\")\n",
    "origin_train = origin_train.query(\"CustomerCareCalls < 15\")\n",
    "\n",
    "# Step 1: Drop rows with missing values\n",
    "data_cleaned = origin_train.dropna()\n",
    "seed = 0\n",
    "\n",
    "# Step 2: Encoding categorical columns (if necessary)\n",
    "label_encoders = {}\n",
    "for column in data_cleaned.select_dtypes(include=['object']).columns:\n",
    "    if column != 'CustomerID' and column != 'Churn':  # Exclude ID and target column\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        data_cleaned[column] = label_encoders[column].fit_transform(data_cleaned[column])\n",
    "\n",
    "# Encode target column 'Churn'\n",
    "le_churn = LabelEncoder()\n",
    "data_cleaned['Churn'] = le_churn.fit_transform(data_cleaned['Churn'])\n",
    "\n",
    "# Step 3: Splitting data into features (X) and target (y)\n",
    "X = data_cleaned.drop(columns=['CustomerID', 'Churn'])\n",
    "y = data_cleaned['Churn']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "# Step 4: Train and evaluate models\n",
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=seed)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=seed)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "\n",
    "rf_accuracy, xgb_accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
